from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import os
from groq import Groq
import google.generativeai as genai
from dotenv import load_dotenv
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()

app = FastAPI()

# API í‚¤ ì„¤ì •
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# Groq í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (Primary)
groq_client = None
if GROQ_API_KEY:
    groq_client = Groq(api_key=GROQ_API_KEY)
    logger.info("âœ… Groq API Keyê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. (Llama 3 í™œì„±í™”)")

# Gemini ì„¤ì • (Fallbackìš©)
if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)
    logger.info("âœ… Google API Keyê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. (Gemini í™œì„±í™”)")

# í˜ë¥´ì†Œë‚˜ ë¡œë“œ
current_dir = os.path.dirname(os.path.abspath(__file__))
persona_path = os.path.join(current_dir, "persona.txt")

try:
    with open(persona_path, "r", encoding="utf-8") as f:
        SYSTEM_PROMPT = f.read()
    logger.info("âœ… í˜ë¥´ì†Œë‚˜ íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ì½ì—ˆìŠµë‹ˆë‹¤.")
except FileNotFoundError:
    SYSTEM_PROMPT = "ë‹¹ì‹ ì€ ì „ë¬¸ í—¬ìŠ¤ íŠ¸ë ˆì´ë„ˆì…ë‹ˆë‹¤."
    logger.warning("âš ï¸ persona.txtë¥¼ ì°¾ì§€ ëª»í•´ ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

class ChatRequest(BaseModel):
    user_id: str
    message: str
    context: str = ""

@app.get("/")
def read_root():
    return {"status": "online", "message": "Gains & Guide AI (Groq + Gemini) Server is Running!"}

@app.post("/chat")
async def chat_with_coach(request: ChatRequest):
    full_prompt = f"{SYSTEM_PROMPT}\n\n[ì‚¬ìš©ì ì •ë³´]\n{request.context}\n\n[ì§ˆë¬¸]\n{request.message}"

    # 1ìˆœìœ„: Groq (Llama 3 70B) ì‚¬ìš© - ì´ˆê³ ì† ì‘ë‹µ
    if groq_client:
        try:
            logger.info("ğŸš€ Groq (Llama 3) ì—”ì§„ìœ¼ë¡œ ì‘ë‹µ ìƒì„± ì¤‘...")
            completion = groq_client.chat.completions.create(
                model="llama3-70b-8192",
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": f"[ë°ì´í„°]\n{request.context}\n\n[ì§ˆë¬¸]\n{request.message}"}
                ],
                temperature=0.7,
                max_tokens=1024,
            )
            return {"response": completion.choices[0].message.content, "engine": "groq"}
        except Exception as e:
            logger.error(f"âŒ Groq ì˜¤ë¥˜ ë°œìƒ, Geminië¡œ ì „í™˜í•©ë‹ˆë‹¤: {str(e)}")

    # 2ìˆœìœ„: Gemini (Fallback) ì‚¬ìš©
    if GOOGLE_API_KEY:
        try:
            logger.info("Fallback: Gemini ì—”ì§„ìœ¼ë¡œ ì‘ë‹µ ìƒì„± ì¤‘...")
            model = genai.GenerativeModel('gemini-1.5-flash-latest')
            response = model.generate_content(full_prompt)
            return {"response": response.text, "engine": "gemini"}
        except Exception as e:
            logger.error(f"âŒ Gemini ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise HTTPException(status_code=500, detail="ëª¨ë“  AI ì—”ì§„ì´ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    raise HTTPException(status_code=500, detail="API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)
